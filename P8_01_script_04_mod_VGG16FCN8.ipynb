{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a3afca",
   "metadata": {},
   "source": [
    "# Projet 8: Participez à la conception d'une voiture autonome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254db8a",
   "metadata": {},
   "source": [
    "## Segmentation des images complexe VGG16 FCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b7650",
   "metadata": {},
   "source": [
    "### Importer les librairies necessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9753fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.3 MB 3.1 kB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 57.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel~=0.35 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.35.1)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 44.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (3.19.3)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 64.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 61.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio<2.0,>=1.37.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (50.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.6)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer~=2.0.0; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.3)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Building wheels for collected packages: clang\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30705 sha256=3720d1be8ede191a0af114edc9b6c1ca3f2526c0a31450418cda8666c88c93a3\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "Successfully built clang\n",
      "\u001b[31mERROR: pyldavis 3.3.1 requires sklearn, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: pandas-ml 0.6.1 requires enum34, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: torchvision 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.10.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torch-tb-profiler 0.3.1 has requirement pandas>=1.0.0, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 2.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 2.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: raiwidgets 0.16.0 has requirement ipython==7.16.1, but you'll have ipython 7.16.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: raiwidgets 0.16.0 has requirement jinja2==2.11.3, but you'll have jinja2 2.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pyldavis 3.3.1 has requirement numpy>=1.20.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pyldavis 3.3.1 has requirement pandas>=1.2.0, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.6 has requirement lightgbm>=2.3.1, but you'll have lightgbm 2.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.6 has requirement pyyaml<6.0.0, but you'll have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.6 has requirement scikit-learn==0.23.2, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 3.1.0 has requirement joblib~=1.0.1, but you'll have joblib 0.14.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: ipython 7.16.3 has requirement jedi<=0.17.2,>=0.10, but you'll have jedi 0.18.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imbalanced-learn 0.7.0 has requirement scikit-learn>=0.23, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imageio 2.15.0 has requirement pillow>=8.3.2, but you'll have pillow 8.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datasets 1.8.0 has requirement tqdm<4.50.0,>=4.27, but you'll have tqdm 4.62.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-train-automl-runtime 1.38.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-automl-runtime 1.38.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.33.0 has requirement azure-graphrbac~=0.60.0, but you'll have azure-graphrbac 0.61.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.33.0 has requirement PyNaCl~=1.4.0, but you'll have pynacl 1.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.33.0 has requirement websocket-client~=0.56.0, but you'll have websocket-client 1.2.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli-core 2.33.0 has requirement knack~=0.9.0, but you'll have knack 0.8.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 1.0.16 has requirement tensorflow<=2.5.0,>=2.3.0, but you'll have tensorflow 2.6.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast, typing-extensions, tensorflow-estimator, numpy, six, clang, tensorboard, keras, flatbuffers, tensorflow\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "Successfully installed clang-5.0 flatbuffers-1.12 gast-0.4.0 keras-2.6.0 numpy-1.19.5 six-1.15.0 tensorboard-2.6.0 tensorflow-2.6.2 tensorflow-estimator-2.6.0 typing-extensions-3.7.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1fd9f71",
   "metadata": {
    "gather": {
     "logged": 1646691412467
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Convolution2D,BatchNormalization,ReLU,LeakyReLU,Add,Activation\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,AveragePooling2D,UpSampling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Activation, MaxPool2D, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6389ebe",
   "metadata": {},
   "source": [
    "### Dèfinir mes fonctions pertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a924c6c",
   "metadata": {
    "gather": {
     "logged": 1646691412617
    }
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + (3*dice_loss(y_true, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9d76d",
   "metadata": {},
   "source": [
    "### Dèfinir les catègories de mes masques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3499c20f",
   "metadata": {
    "gather": {
     "logged": 1646691417539
    }
   },
   "outputs": [],
   "source": [
    "cats = {'void': [0, 1, 2, 3, 4, 5, 6],\n",
    " 'flat': [7, 8, 9, 10],\n",
    " 'construction': [11, 12, 13, 14, 15, 16],\n",
    " 'object': [17, 18, 19, 20],\n",
    " 'nature': [21, 22],\n",
    " 'sky': [23],\n",
    " 'human': [24, 25],\n",
    " 'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cbfa7",
   "metadata": {},
   "source": [
    "### Dèfinir les emplacements de mes images et masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3cb371d",
   "metadata": {
    "gather": {
     "logged": 1646691434069
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbre Image: 5000\n",
      "Nbre Mask: 5000\n",
      "0003.jpg 0003.jpg\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'aug_dataset/images'\n",
    "mask_dir = 'aug_dataset/masks'\n",
    "image_list = os.listdir(image_dir)\n",
    "mask_list = os.listdir(mask_dir)\n",
    "image_list.sort()\n",
    "mask_list.sort()\n",
    "print(f'Nbre Image: {len(image_list)}\\nNbre Mask: {len(mask_list)}')\n",
    "\n",
    "# sanity check\n",
    "for i in range(len(image_list)):\n",
    "    assert image_list[i] == mask_list[i]\n",
    "print(image_list[2], mask_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f121c41b",
   "metadata": {
    "gather": {
     "logged": 1646691441043
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbre Image test: 5000\n",
      "Nbre Mask test: 5000\n",
      "0003.jpg 0003.jpg\n"
     ]
    }
   ],
   "source": [
    "test_image_dir = 'data_f/image_val'\n",
    "test_mask_dir = 'data_f/masque_val'\n",
    "test_image_list = os.listdir(image_dir)\n",
    "test_mask_list = os.listdir(mask_dir)\n",
    "test_image_list.sort()\n",
    "test_mask_list.sort()\n",
    "print(f'Nbre Image test: {len(test_image_list)}\\nNbre Mask test: {len(test_mask_list)}')\n",
    "\n",
    "# sanity check\n",
    "for i in range(len(image_list)):\n",
    "    assert test_image_list[i] == test_mask_list[i]\n",
    "print(test_image_list[2], test_mask_list[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7894ca",
   "metadata": {},
   "source": [
    "### Dèfinir les différents paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60f92837",
   "metadata": {
    "gather": {
     "logged": 1646691449393
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "samples = 5000\n",
    "steps = samples//batch_size\n",
    "img_height, img_width = 256,256\n",
    "classes = 8\n",
    "filters_n = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94781ff4",
   "metadata": {},
   "source": [
    "### Créer la class seg_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415eb0df",
   "metadata": {
    "gather": {
     "logged": 1646691449544
    }
   },
   "outputs": [],
   "source": [
    "class seg_gen(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.random.randint(0, samples, batch_size)\n",
    "        batch_x, batch_y = [], []\n",
    "        for i in idx:\n",
    "            _image = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}', target_size=(img_height, img_width)))/255.   \n",
    "            img = image.img_to_array(image.load_img(f'{mask_dir}/{mask_list[i]}', grayscale=True, target_size=(img_height, img_width)))\n",
    "            img = np.squeeze(img)\n",
    "            mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "            for i in range(-1, 34):\n",
    "                if i in cats['void']:\n",
    "                    mask[:,:,0] = np.logical_or(mask[:,:,0],(img==i))\n",
    "                elif i in cats['flat']:\n",
    "                    mask[:,:,1] = np.logical_or(mask[:,:,1],(img==i))\n",
    "                elif i in cats['construction']:\n",
    "                    mask[:,:,2] = np.logical_or(mask[:,:,2],(img==i))\n",
    "                elif i in cats['object']:\n",
    "                    mask[:,:,3] = np.logical_or(mask[:,:,3],(img==i))\n",
    "                elif i in cats['nature']:\n",
    "                    mask[:,:,4] = np.logical_or(mask[:,:,4],(img==i))\n",
    "                elif i in cats['sky']:\n",
    "                    mask[:,:,5] = np.logical_or(mask[:,:,5],(img==i))\n",
    "                elif i in cats['human']:\n",
    "                    mask[:,:,6] = np.logical_or(mask[:,:,6],(img==i))\n",
    "                elif i in cats['vehicle']:\n",
    "                    mask[:,:,7] = np.logical_or(mask[:,:,7],(img==i))\n",
    "            mask = np.resize(mask,(img_height,img_width, 8))\n",
    "            batch_x.append(_image)\n",
    "            batch_y.append(mask)\n",
    "            X = np.array(batch_x)\n",
    "            Y = np.array(batch_y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f01ef225",
   "metadata": {
    "gather": {
     "logged": 1646691449733
    }
   },
   "outputs": [],
   "source": [
    "train_gen = seg_gen(image_list, mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "515b8180",
   "metadata": {
    "gather": {
     "logged": 1646691452795
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((16, 256, 256, 3), (16, 256, 256, 8))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X, Y in train_gen:\n",
    "    break\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22003834",
   "metadata": {},
   "source": [
    "### Dèfinir le modèle VGG16FCN8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f23a0",
   "metadata": {},
   "source": [
    "### Modèle de segmentation - FCN+Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80327c08",
   "metadata": {
    "gather": {
     "logged": 1646691452954
    }
   },
   "outputs": [],
   "source": [
    "def fcn(vgg, classes = classes, fcn8 = False, fcn16 = False):\n",
    "    pool5 = vgg.get_layer('block5_pool').output \n",
    "    pool4 = vgg.get_layer('block4_pool').output\n",
    "    pool3 = vgg.get_layer('block3_pool').output\n",
    "    \n",
    "    conv_6 = Conv2D(1024, (7, 7), activation='relu', padding='same', name=\"conv_6\")(pool5)\n",
    "    conv_7 = Conv2D(1024, (1, 1), activation='relu', padding='same', name=\"conv_7\")(conv_6)\n",
    "    \n",
    "    conv_8 = Conv2D(classes, (1, 1), activation='relu', padding='same', name=\"conv_8\")(pool4)\n",
    "    conv_9 = Conv2D(classes, (1, 1), activation='relu', padding='same', name=\"conv_9\")(pool3)\n",
    "    \n",
    "    deconv_7 = Conv2DTranspose(classes, kernel_size=(2,2), strides=(2,2))(conv_7)\n",
    "    add_1 = Add()([deconv_7, conv_8])\n",
    "    deconv_8 = Conv2DTranspose(classes, kernel_size=(2,2), strides=(2,2))(add_1)\n",
    "    add_2 = Add()([deconv_8, conv_9])\n",
    "    deconv_9 = Conv2DTranspose(classes, kernel_size=(8,8), strides=(8,8))(add_2)\n",
    "    \n",
    "    if fcn8 :\n",
    "        output_layer = Activation('softmax')(deconv_9)\n",
    "    elif fcn16 :\n",
    "        deconv_10 = Conv2DTranspose(classes, kernel_size=(16,16), strides=(16,16))(add_1)\n",
    "        output_layer = Activation('softmax')(deconv_10)\n",
    "    else :\n",
    "        deconv_11 = Conv2DTranspose(classes, kernel_size=(32,32), strides=(32,32))(conv_7)\n",
    "        output_layer = Activation('softmax')(deconv_11)\n",
    "    \n",
    "    model = Model(inputs=vgg.input, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a71bd866",
   "metadata": {
    "gather": {
     "logged": 1646691453114
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"model_VGG16FCN_check.h5\", save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=3, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9146573d",
   "metadata": {
    "gather": {
     "logged": 1646691469399
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "58900480/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f4a877",
   "metadata": {
    "gather": {
     "logged": 1646691469736
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 256, 256, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 128, 128, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 128, 128, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 128, 128, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 64, 64, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 64, 64, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 64, 64, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 64, 64, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 32, 32, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 32, 32, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 32, 32, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 32, 32, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 16, 16, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 16, 16, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 16, 16, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 16, 16, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 8, 8, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " conv_6 (Conv2D)                (None, 8, 8, 1024)   25691136    ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " conv_7 (Conv2D)                (None, 8, 8, 1024)   1049600     ['conv_6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 16, 16, 8)   32776       ['conv_7[0][0]']                 \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv_8 (Conv2D)                (None, 16, 16, 8)    4104        ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 16, 8)    0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv_8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 8)   264         ['add[0][0]']                    \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv_9 (Conv2D)                (None, 32, 32, 8)    2056        ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 8)    0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv_9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 8)  4104       ['add_1[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 8)  0           ['conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41,498,728\n",
      "Trainable params: 41,498,728\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = fcn(vgg, fcn8=True)\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b15a554",
   "metadata": {
    "gather": {
     "logged": 1646692933508
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-22f8966706a9>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5772 - accuracy: 0.4160WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 228s 557ms/step - loss: 1.5772 - accuracy: 0.4160\n",
      "Epoch 2/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3159 - accuracy: 0.4925WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 174s 552ms/step - loss: 1.3159 - accuracy: 0.4925\n",
      "Epoch 3/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1907 - accuracy: 0.5447WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 175s 555ms/step - loss: 1.1907 - accuracy: 0.5447\n",
      "Epoch 4/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1002 - accuracy: 0.5782WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 174s 549ms/step - loss: 1.1002 - accuracy: 0.5782\n",
      "Epoch 5/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0532 - accuracy: 0.5964WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 174s 551ms/step - loss: 1.0532 - accuracy: 0.5964\n",
      "Epoch 6/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.6126WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 174s 551ms/step - loss: 1.0070 - accuracy: 0.6126\n",
      "Epoch 7/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9776 - accuracy: 0.6222WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 175s 554ms/step - loss: 0.9776 - accuracy: 0.6222\n",
      "Epoch 8/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9521 - accuracy: 0.6302WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 172s 547ms/step - loss: 0.9521 - accuracy: 0.6302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa724429880>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60c6f947",
   "metadata": {
    "gather": {
     "logged": 1646692937155
    }
   },
   "outputs": [],
   "source": [
    "model.save('model_VGG16FCN.h5')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
