{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a3afca",
   "metadata": {},
   "source": [
    "# Projet 8: Participez à la conception d'une voiture autonome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254db8a",
   "metadata": {},
   "source": [
    "## Segmentation des images complexe PSPNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b7650",
   "metadata": {},
   "source": [
    "### Importer les librairies necessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9753fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.3 MB 3.4 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 30.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta~=0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0,>=1.37.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.43.0)\n",
      "Collecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 69.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 64.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (3.19.3)\n",
      "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 70.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (50.3.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer~=2.0.0; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.3)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Building wheels for collected packages: clang\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30705 sha256=9f86a5984e4a37501bbee9b6e4039946a8a08746e0597bc142a2e064c9d988be\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "Successfully built clang\n",
      "\u001b[31mERROR: pyldavis 3.3.1 requires sklearn, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: pandas-ml 0.6.1 requires enum34, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: torchvision 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.10.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torch-tb-profiler 0.3.1 has requirement pandas>=1.0.0, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 2.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 2.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: raiwidgets 0.16.0 has requirement ipython==7.16.1, but you'll have ipython 7.16.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: raiwidgets 0.16.0 has requirement jinja2==2.11.3, but you'll have jinja2 2.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pyldavis 3.3.1 has requirement numpy>=1.20.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pyldavis 3.3.1 has requirement pandas>=1.2.0, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.6 has requirement lightgbm>=2.3.1, but you'll have lightgbm 2.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.6 has requirement pyyaml<6.0.0, but you'll have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.6 has requirement scikit-learn==0.23.2, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 3.1.0 has requirement joblib~=1.0.1, but you'll have joblib 0.14.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: ipython 7.16.3 has requirement jedi<=0.17.2,>=0.10, but you'll have jedi 0.18.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imbalanced-learn 0.7.0 has requirement scikit-learn>=0.23, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imageio 2.15.0 has requirement pillow>=8.3.2, but you'll have pillow 8.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datasets 1.8.0 has requirement tqdm<4.50.0,>=4.27, but you'll have tqdm 4.62.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-train-automl-runtime 1.38.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-automl-runtime 1.38.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.33.0 has requirement azure-graphrbac~=0.60.0, but you'll have azure-graphrbac 0.61.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.33.0 has requirement PyNaCl~=1.4.0, but you'll have pynacl 1.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.33.0 has requirement websocket-client~=0.56.0, but you'll have websocket-client 1.2.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli-core 2.33.0 has requirement knack~=0.9.0, but you'll have knack 0.8.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 1.0.16 has requirement tensorflow<=2.5.0,>=2.3.0, but you'll have tensorflow 2.6.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: clang, numpy, tensorboard, keras, typing-extensions, tensorflow-estimator, flatbuffers, gast, six, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "Successfully installed clang-5.0 flatbuffers-1.12 gast-0.4.0 keras-2.6.0 numpy-1.19.5 six-1.15.0 tensorboard-2.6.0 tensorflow-2.6.2 tensorflow-estimator-2.6.0 typing-extensions-3.7.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880b346e",
   "metadata": {
    "gather": {
     "logged": 1646686926556
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation_models\n",
      "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
      "Collecting image-classifiers==1.0.0\n",
      "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from segmentation_models) (1.0.8)\n",
      "Collecting efficientnet==1.0.0\n",
      "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: h5py in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.22.2)\n",
      "Requirement already satisfied: scikit-image in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from efficientnet==1.0.0->segmentation_models) (0.19.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.0.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.15.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (21.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2022.2.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from networkx>=2.2->scikit-image->efficientnet==1.0.0->segmentation_models) (5.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging>=20.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.6)\n",
      "Installing collected packages: image-classifiers, efficientnet, segmentation-models\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fd9f71",
   "metadata": {
    "gather": {
     "logged": 1646686955551
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Convolution2D,BatchNormalization,ReLU,LeakyReLU,Add,Activation\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,AveragePooling2D,UpSampling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Activation, MaxPool2D, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1833dbf3",
   "metadata": {
    "gather": {
     "logged": 1646686957671
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n",
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "%env SM_FRAMEWORK=tf.keras\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6389ebe",
   "metadata": {},
   "source": [
    "### Dèfinir mes fonctions pertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a924c6c",
   "metadata": {
    "gather": {
     "logged": 1646686963458
    }
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + (3*dice_loss(y_true, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9d76d",
   "metadata": {},
   "source": [
    "### Dèfinir les catègories de mes masques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3499c20f",
   "metadata": {
    "gather": {
     "logged": 1646686967930
    }
   },
   "outputs": [],
   "source": [
    "cats = {'void': [0, 1, 2, 3, 4, 5, 6],\n",
    " 'flat': [7, 8, 9, 10],\n",
    " 'construction': [11, 12, 13, 14, 15, 16],\n",
    " 'object': [17, 18, 19, 20],\n",
    " 'nature': [21, 22],\n",
    " 'sky': [23],\n",
    " 'human': [24, 25],\n",
    " 'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cbfa7",
   "metadata": {},
   "source": [
    "### Dèfinir les emplacements de mes fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cb371d",
   "metadata": {
    "gather": {
     "logged": 1646686973392
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbre Image: 5000\n",
      "Nbre Mask: 5000\n",
      "0003.jpg 0003.jpg\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'aug_dataset/images'\n",
    "mask_dir = 'aug_dataset/masks'\n",
    "image_list = os.listdir(image_dir)\n",
    "mask_list = os.listdir(mask_dir)\n",
    "image_list.sort()\n",
    "mask_list.sort()\n",
    "print(f'Nbre Image: {len(image_list)}\\nNbre Mask: {len(mask_list)}')\n",
    "\n",
    "# sanity check\n",
    "for i in range(len(image_list)):\n",
    "    assert image_list[i] == mask_list[i]\n",
    "print(image_list[2], mask_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f121c41b",
   "metadata": {
    "gather": {
     "logged": 1646686978343
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbre Image test: 5000\n",
      "Nbre Mask test: 5000\n",
      "0003.jpg 0003.jpg\n"
     ]
    }
   ],
   "source": [
    "test_image_dir = 'data_f/image_val'\n",
    "test_mask_dir = 'data_f/masque_val'\n",
    "test_image_list = os.listdir(image_dir)\n",
    "test_mask_list = os.listdir(mask_dir)\n",
    "test_image_list.sort()\n",
    "test_mask_list.sort()\n",
    "print(f'Nbre Image test: {len(test_image_list)}\\nNbre Mask test: {len(test_mask_list)}')\n",
    "\n",
    "# sanity check\n",
    "for i in range(len(image_list)):\n",
    "    assert test_image_list[i] == test_mask_list[i]\n",
    "print(test_image_list[2], test_mask_list[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7894ca",
   "metadata": {},
   "source": [
    "### Dèfinir les différents paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f92837",
   "metadata": {
    "gather": {
     "logged": 1646686983234
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "samples = 5000\n",
    "steps = samples//batch_size\n",
    "img_height, img_width = 384,384\n",
    "classes = 8\n",
    "filters_n = 64\n",
    "img_size = (384, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94781ff4",
   "metadata": {},
   "source": [
    "### Créer la class seg_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "415eb0df",
   "metadata": {
    "gather": {
     "logged": 1646686987665
    }
   },
   "outputs": [],
   "source": [
    "class seg_gen(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.random.randint(0, samples, batch_size)\n",
    "        batch_x, batch_y = [], []\n",
    "        for i in idx:\n",
    "            _image = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}', target_size=(img_height, img_width)))/255.   \n",
    "            img = image.img_to_array(image.load_img(f'{mask_dir}/{mask_list[i]}', grayscale=True, target_size=(img_height, img_width)))\n",
    "            img = np.squeeze(img)\n",
    "            mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "            for i in range(-1, 34):\n",
    "                if i in cats['void']:\n",
    "                    mask[:,:,0] = np.logical_or(mask[:,:,0],(img==i))\n",
    "                elif i in cats['flat']:\n",
    "                    mask[:,:,1] = np.logical_or(mask[:,:,1],(img==i))\n",
    "                elif i in cats['construction']:\n",
    "                    mask[:,:,2] = np.logical_or(mask[:,:,2],(img==i))\n",
    "                elif i in cats['object']:\n",
    "                    mask[:,:,3] = np.logical_or(mask[:,:,3],(img==i))\n",
    "                elif i in cats['nature']:\n",
    "                    mask[:,:,4] = np.logical_or(mask[:,:,4],(img==i))\n",
    "                elif i in cats['sky']:\n",
    "                    mask[:,:,5] = np.logical_or(mask[:,:,5],(img==i))\n",
    "                elif i in cats['human']:\n",
    "                    mask[:,:,6] = np.logical_or(mask[:,:,6],(img==i))\n",
    "                elif i in cats['vehicle']:\n",
    "                    mask[:,:,7] = np.logical_or(mask[:,:,7],(img==i))\n",
    "            mask = np.resize(mask,(img_height,img_width, 8))\n",
    "            batch_x.append(_image)\n",
    "            batch_y.append(mask)\n",
    "            X = np.array(batch_x)\n",
    "            Y = np.array(batch_y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01ef225",
   "metadata": {
    "gather": {
     "logged": 1646686992539
    }
   },
   "outputs": [],
   "source": [
    "train_gen = seg_gen(image_list, mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515b8180",
   "metadata": {
    "gather": {
     "logged": 1646687000193
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((16, 384, 384, 3), (16, 384, 384, 8))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X, Y in train_gen:\n",
    "    break\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22003834",
   "metadata": {},
   "source": [
    "### Dèfinir le modèle PSPNet (Réseau d’analyse pyramidale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da6cdbb",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80327c08",
   "metadata": {
    "gather": {
     "logged": 1646687011896
    }
   },
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet50'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a71bd866",
   "metadata": {
    "gather": {
     "logged": 1646687018540
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"model_PSPNet_check.h5\", save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=3, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02f4a877",
   "metadata": {
    "gather": {
     "logged": 1646687198419
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 384, 384, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " bn_data (BatchNormalization)   (None, 384, 384, 3)  9           ['data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d_18 (ZeroPadding  (None, 390, 390, 3)  0          ['bn_data[0][0]']                \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv0 (Conv2D)                 (None, 192, 192, 64  9408        ['zero_padding2d_18[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn0 (BatchNormalization)       (None, 192, 192, 64  256         ['conv0[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu0 (Activation)             (None, 192, 192, 64  0           ['bn0[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_19 (ZeroPadding  (None, 194, 194, 64  0          ['relu0[0][0]']                  \n",
      " 2D)                            )                                                                 \n",
      "                                                                                                  \n",
      " pooling0 (MaxPooling2D)        (None, 96, 96, 64)   0           ['zero_padding2d_19[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_bn1 (BatchNormali  (None, 96, 96, 64)  256         ['pooling0[0][0]']               \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu1 (Activation  (None, 96, 96, 64)  0           ['stage1_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv1 (Conv2D)    (None, 96, 96, 64)   4096        ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_bn2 (BatchNormali  (None, 96, 96, 64)  256         ['stage1_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu2 (Activation  (None, 96, 96, 64)  0           ['stage1_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_20 (ZeroPadding  (None, 98, 98, 64)  0           ['stage1_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit1_conv2 (Conv2D)    (None, 96, 96, 64)   36864       ['zero_padding2d_20[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_bn3 (BatchNormali  (None, 96, 96, 64)  256         ['stage1_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu3 (Activation  (None, 96, 96, 64)  0           ['stage1_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv3 (Conv2D)    (None, 96, 96, 256)  16384       ['stage1_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_sc (Conv2D)       (None, 96, 96, 256)  16384       ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 96, 96, 256)  0           ['stage1_unit1_conv3[0][0]',     \n",
      "                                                                  'stage1_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage1_unit2_bn1 (BatchNormali  (None, 96, 96, 256)  1024       ['add_16[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu1 (Activation  (None, 96, 96, 256)  0          ['stage1_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv1 (Conv2D)    (None, 96, 96, 64)   16384       ['stage1_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit2_bn2 (BatchNormali  (None, 96, 96, 64)  256         ['stage1_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu2 (Activation  (None, 96, 96, 64)  0           ['stage1_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_21 (ZeroPadding  (None, 98, 98, 64)  0           ['stage1_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit2_conv2 (Conv2D)    (None, 96, 96, 64)   36864       ['zero_padding2d_21[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit2_bn3 (BatchNormali  (None, 96, 96, 64)  256         ['stage1_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu3 (Activation  (None, 96, 96, 64)  0           ['stage1_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv3 (Conv2D)    (None, 96, 96, 256)  16384       ['stage1_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 96, 96, 256)  0           ['stage1_unit2_conv3[0][0]',     \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " stage1_unit3_bn1 (BatchNormali  (None, 96, 96, 256)  1024       ['add_17[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu1 (Activation  (None, 96, 96, 256)  0          ['stage1_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv1 (Conv2D)    (None, 96, 96, 64)   16384       ['stage1_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit3_bn2 (BatchNormali  (None, 96, 96, 64)  256         ['stage1_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu2 (Activation  (None, 96, 96, 64)  0           ['stage1_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_22 (ZeroPadding  (None, 98, 98, 64)  0           ['stage1_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit3_conv2 (Conv2D)    (None, 96, 96, 64)   36864       ['zero_padding2d_22[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit3_bn3 (BatchNormali  (None, 96, 96, 64)  256         ['stage1_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu3 (Activation  (None, 96, 96, 64)  0           ['stage1_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv3 (Conv2D)    (None, 96, 96, 256)  16384       ['stage1_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 96, 96, 256)  0           ['stage1_unit3_conv3[0][0]',     \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit1_bn1 (BatchNormali  (None, 96, 96, 256)  1024       ['add_18[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu1 (Activation  (None, 96, 96, 256)  0          ['stage2_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv1 (Conv2D)    (None, 96, 96, 128)  32768       ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_bn2 (BatchNormali  (None, 96, 96, 128)  512        ['stage2_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu2 (Activation  (None, 96, 96, 128)  0          ['stage2_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_23 (ZeroPadding  (None, 98, 98, 128)  0          ['stage2_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit1_conv2 (Conv2D)    (None, 48, 48, 128)  147456      ['zero_padding2d_23[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit1_bn3 (BatchNormali  (None, 48, 48, 128)  512        ['stage2_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu3 (Activation  (None, 48, 48, 128)  0          ['stage2_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv3 (Conv2D)    (None, 48, 48, 512)  65536       ['stage2_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_sc (Conv2D)       (None, 48, 48, 512)  131072      ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 48, 48, 512)  0           ['stage2_unit1_conv3[0][0]',     \n",
      "                                                                  'stage2_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage2_unit2_bn1 (BatchNormali  (None, 48, 48, 512)  2048       ['add_19[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu1 (Activation  (None, 48, 48, 512)  0          ['stage2_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv1 (Conv2D)    (None, 48, 48, 128)  65536       ['stage2_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit2_bn2 (BatchNormali  (None, 48, 48, 128)  512        ['stage2_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu2 (Activation  (None, 48, 48, 128)  0          ['stage2_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_24 (ZeroPadding  (None, 50, 50, 128)  0          ['stage2_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit2_conv2 (Conv2D)    (None, 48, 48, 128)  147456      ['zero_padding2d_24[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit2_bn3 (BatchNormali  (None, 48, 48, 128)  512        ['stage2_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu3 (Activation  (None, 48, 48, 128)  0          ['stage2_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv3 (Conv2D)    (None, 48, 48, 512)  65536       ['stage2_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 48, 48, 512)  0           ['stage2_unit2_conv3[0][0]',     \n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit3_bn1 (BatchNormali  (None, 48, 48, 512)  2048       ['add_20[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu1 (Activation  (None, 48, 48, 512)  0          ['stage2_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv1 (Conv2D)    (None, 48, 48, 128)  65536       ['stage2_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit3_bn2 (BatchNormali  (None, 48, 48, 128)  512        ['stage2_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu2 (Activation  (None, 48, 48, 128)  0          ['stage2_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_25 (ZeroPadding  (None, 50, 50, 128)  0          ['stage2_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit3_conv2 (Conv2D)    (None, 48, 48, 128)  147456      ['zero_padding2d_25[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit3_bn3 (BatchNormali  (None, 48, 48, 128)  512        ['stage2_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu3 (Activation  (None, 48, 48, 128)  0          ['stage2_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv3 (Conv2D)    (None, 48, 48, 512)  65536       ['stage2_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 48, 48, 512)  0           ['stage2_unit3_conv3[0][0]',     \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit4_bn1 (BatchNormali  (None, 48, 48, 512)  2048       ['add_21[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu1 (Activation  (None, 48, 48, 512)  0          ['stage2_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv1 (Conv2D)    (None, 48, 48, 128)  65536       ['stage2_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit4_bn2 (BatchNormali  (None, 48, 48, 128)  512        ['stage2_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu2 (Activation  (None, 48, 48, 128)  0          ['stage2_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_26 (ZeroPadding  (None, 50, 50, 128)  0          ['stage2_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit4_conv2 (Conv2D)    (None, 48, 48, 128)  147456      ['zero_padding2d_26[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit4_bn3 (BatchNormali  (None, 48, 48, 128)  512        ['stage2_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu3 (Activation  (None, 48, 48, 128)  0          ['stage2_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv3 (Conv2D)    (None, 48, 48, 512)  65536       ['stage2_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 48, 48, 512)  0           ['stage2_unit4_conv3[0][0]',     \n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit1_bn1 (BatchNormali  (None, 48, 48, 512)  2048       ['add_22[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu1 (Activation  (None, 48, 48, 512)  0          ['stage3_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " psp_level1_pooling (AveragePoo  (None, 1, 1, 512)   0           ['stage3_unit1_relu1[0][0]']     \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " psp_level2_pooling (AveragePoo  (None, 2, 2, 512)   0           ['stage3_unit1_relu1[0][0]']     \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " psp_level3_pooling (AveragePoo  (None, 3, 3, 512)   0           ['stage3_unit1_relu1[0][0]']     \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " psp_level6_pooling (AveragePoo  (None, 6, 6, 512)   0           ['stage3_unit1_relu1[0][0]']     \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " psp_level1_conv (Conv2D)       (None, 1, 1, 512)    262144      ['psp_level1_pooling[0][0]']     \n",
      "                                                                                                  \n",
      " psp_level2_conv (Conv2D)       (None, 2, 2, 512)    262144      ['psp_level2_pooling[0][0]']     \n",
      "                                                                                                  \n",
      " psp_level3_conv (Conv2D)       (None, 3, 3, 512)    262144      ['psp_level3_pooling[0][0]']     \n",
      "                                                                                                  \n",
      " psp_level6_conv (Conv2D)       (None, 6, 6, 512)    262144      ['psp_level6_pooling[0][0]']     \n",
      "                                                                                                  \n",
      " psp_level1_bn (BatchNormalizat  (None, 1, 1, 512)   2048        ['psp_level1_conv[0][0]']        \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " psp_level2_bn (BatchNormalizat  (None, 2, 2, 512)   2048        ['psp_level2_conv[0][0]']        \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " psp_level3_bn (BatchNormalizat  (None, 3, 3, 512)   2048        ['psp_level3_conv[0][0]']        \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " psp_level6_bn (BatchNormalizat  (None, 6, 6, 512)   2048        ['psp_level6_conv[0][0]']        \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " psp_level1_relu (Activation)   (None, 1, 1, 512)    0           ['psp_level1_bn[0][0]']          \n",
      "                                                                                                  \n",
      " psp_level2_relu (Activation)   (None, 2, 2, 512)    0           ['psp_level2_bn[0][0]']          \n",
      "                                                                                                  \n",
      " psp_level3_relu (Activation)   (None, 3, 3, 512)    0           ['psp_level3_bn[0][0]']          \n",
      "                                                                                                  \n",
      " psp_level6_relu (Activation)   (None, 6, 6, 512)    0           ['psp_level6_bn[0][0]']          \n",
      "                                                                                                  \n",
      " psp_level1_upsampling (UpSampl  (None, 48, 48, 512)  0          ['psp_level1_relu[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " psp_level2_upsampling (UpSampl  (None, 48, 48, 512)  0          ['psp_level2_relu[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " psp_level3_upsampling (UpSampl  (None, 48, 48, 512)  0          ['psp_level3_relu[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " psp_level6_upsampling (UpSampl  (None, 48, 48, 512)  0          ['psp_level6_relu[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " psp_concat (Concatenate)       (None, 48, 48, 2560  0           ['stage3_unit1_relu1[0][0]',     \n",
      "                                )                                 'psp_level1_upsampling[0][0]',  \n",
      "                                                                  'psp_level2_upsampling[0][0]',  \n",
      "                                                                  'psp_level3_upsampling[0][0]',  \n",
      "                                                                  'psp_level6_upsampling[0][0]']  \n",
      "                                                                                                  \n",
      " aggregation_conv (Conv2D)      (None, 48, 48, 512)  1310720     ['psp_concat[0][0]']             \n",
      "                                                                                                  \n",
      " aggregation_bn (BatchNormaliza  (None, 48, 48, 512)  2048       ['aggregation_conv[0][0]']       \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " aggregation_relu (Activation)  (None, 48, 48, 512)  0           ['aggregation_bn[0][0]']         \n",
      "                                                                                                  \n",
      " final_conv (Conv2D)            (None, 48, 48, 8)    36872       ['aggregation_relu[0][0]']       \n",
      "                                                                                                  \n",
      " final_upsampling (UpSampling2D  (None, 384, 384, 8)  0          ['final_conv[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 384, 384, 8)  0           ['final_upsampling[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,858,641\n",
      "Trainable params: 3,844,811\n",
      "Non-trainable params: 13,830\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = sm.PSPNet(BACKBONE, encoder_weights='imagenet', classes=classes ,  input_shape=(*img_size, 3))\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b15a554",
   "metadata": {
    "gather": {
     "logged": 1646689138249
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-22f8966706a9>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1344 - accuracy: 0.5714WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 248s 757ms/step - loss: 1.1344 - accuracy: 0.5714\n",
      "Epoch 2/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9887 - accuracy: 0.6180WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 240s 758ms/step - loss: 0.9887 - accuracy: 0.6180\n",
      "Epoch 3/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9408 - accuracy: 0.6359WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 239s 757ms/step - loss: 0.9408 - accuracy: 0.6359\n",
      "Epoch 4/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9065 - accuracy: 0.6466WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 237s 751ms/step - loss: 0.9065 - accuracy: 0.6466\n",
      "Epoch 5/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8956 - accuracy: 0.6503WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 239s 756ms/step - loss: 0.8956 - accuracy: 0.6503\n",
      "Epoch 6/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8599 - accuracy: 0.6633WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 240s 758ms/step - loss: 0.8599 - accuracy: 0.6633\n",
      "Epoch 7/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8487 - accuracy: 0.6663WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 239s 756ms/step - loss: 0.8487 - accuracy: 0.6663\n",
      "Epoch 8/8\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8349 - accuracy: 0.6723WARNING:tensorflow:Can save best model only with val_loss available, skipping.\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "312/312 [==============================] - 238s 751ms/step - loss: 0.8349 - accuracy: 0.6723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe210053460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60c6f947",
   "metadata": {
    "gather": {
     "logged": 1646689139051
    }
   },
   "outputs": [],
   "source": [
    "model.save('model_PSPNet.h5')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
